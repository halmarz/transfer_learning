{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = blue tit\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "\n",
      "Item no.: 1 --> Item name = crow\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "\n",
    "from google_images_download import google_images_download\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\":\"blue tit\",\"limit\":100,\"print_urls\":False,\"format\":\"jpg\", \"size\":\">400*300\"}\n",
    "paths = response.download(arguments)\n",
    "arguments = {\"keywords\":\"crow\",\"limit\":100,\"print_urls\":False, \"format\":\"jpg\", \"size\":\">400*300\"}\n",
    "paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learing with MobileNet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNet(\n",
    "    input_shape =(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_12  (None, 1024)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,229,889\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = keras.Input(shape =(224, 224, 3))\n",
    "x = base_model(inputs) \n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  \n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=base_model.output\n",
    "x=keras.layers.GlobalAveragePooling2D()(x)\n",
    "x=keras.layers.Dense(1024,activation='relu')(x) \n",
    "x=keras.layers.Dense(1024,activation='relu')(x) \n",
    "x=keras.layers.Dense(512,activation='relu')(x) \n",
    "preds=Dense(2,activation='softmax')(x) \n",
    "\n",
    "model=keras.Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_13\n",
      "1 conv1\n",
      "2 conv1_bn\n",
      "3 conv1_relu\n",
      "4 conv_dw_1\n",
      "5 conv_dw_1_bn\n",
      "6 conv_dw_1_relu\n",
      "7 conv_pw_1\n",
      "8 conv_pw_1_bn\n",
      "9 conv_pw_1_relu\n",
      "10 conv_pad_2\n",
      "11 conv_dw_2\n",
      "12 conv_dw_2_bn\n",
      "13 conv_dw_2_relu\n",
      "14 conv_pw_2\n",
      "15 conv_pw_2_bn\n",
      "16 conv_pw_2_relu\n",
      "17 conv_dw_3\n",
      "18 conv_dw_3_bn\n",
      "19 conv_dw_3_relu\n",
      "20 conv_pw_3\n",
      "21 conv_pw_3_bn\n",
      "22 conv_pw_3_relu\n",
      "23 conv_pad_4\n",
      "24 conv_dw_4\n",
      "25 conv_dw_4_bn\n",
      "26 conv_dw_4_relu\n",
      "27 conv_pw_4\n",
      "28 conv_pw_4_bn\n",
      "29 conv_pw_4_relu\n",
      "30 conv_dw_5\n",
      "31 conv_dw_5_bn\n",
      "32 conv_dw_5_relu\n",
      "33 conv_pw_5\n",
      "34 conv_pw_5_bn\n",
      "35 conv_pw_5_relu\n",
      "36 conv_pad_6\n",
      "37 conv_dw_6\n",
      "38 conv_dw_6_bn\n",
      "39 conv_dw_6_relu\n",
      "40 conv_pw_6\n",
      "41 conv_pw_6_bn\n",
      "42 conv_pw_6_relu\n",
      "43 conv_dw_7\n",
      "44 conv_dw_7_bn\n",
      "45 conv_dw_7_relu\n",
      "46 conv_pw_7\n",
      "47 conv_pw_7_bn\n",
      "48 conv_pw_7_relu\n",
      "49 conv_dw_8\n",
      "50 conv_dw_8_bn\n",
      "51 conv_dw_8_relu\n",
      "52 conv_pw_8\n",
      "53 conv_pw_8_bn\n",
      "54 conv_pw_8_relu\n",
      "55 conv_dw_9\n",
      "56 conv_dw_9_bn\n",
      "57 conv_dw_9_relu\n",
      "58 conv_pw_9\n",
      "59 conv_pw_9_bn\n",
      "60 conv_pw_9_relu\n",
      "61 conv_dw_10\n",
      "62 conv_dw_10_bn\n",
      "63 conv_dw_10_relu\n",
      "64 conv_pw_10\n",
      "65 conv_pw_10_bn\n",
      "66 conv_pw_10_relu\n",
      "67 conv_dw_11\n",
      "68 conv_dw_11_bn\n",
      "69 conv_dw_11_relu\n",
      "70 conv_pw_11\n",
      "71 conv_pw_11_bn\n",
      "72 conv_pw_11_relu\n",
      "73 conv_pad_12\n",
      "74 conv_dw_12\n",
      "75 conv_dw_12_bn\n",
      "76 conv_dw_12_relu\n",
      "77 conv_pw_12\n",
      "78 conv_pw_12_bn\n",
      "79 conv_pw_12_relu\n",
      "80 conv_dw_13\n",
      "81 conv_dw_13_bn\n",
      "82 conv_dw_13_relu\n",
      "83 conv_pw_13\n",
      "84 conv_pw_13_bn\n",
      "85 conv_pw_13_relu\n",
      "86 global_average_pooling2d_13\n",
      "87 dense_31\n",
      "88 dense_32\n",
      "89 dense_33\n",
      "90 dense_34\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhalama\\AppData\\Local\\Temp\\ipykernel_10496\\609897027.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=train_ds,epochs=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_13\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [61], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m train_ds, validation_ds, test_ds \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcats_vs_dogs\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     split\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtrain[:40\u001b[39m\u001b[39m%\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrain[40\u001b[39m\u001b[39m%\u001b[39m\u001b[39m:50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrain[50\u001b[39m\u001b[39m%\u001b[39m\u001b[39m:60\u001b[39m\u001b[39m%\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m     as_supervised\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m,loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m model\u001b[39m.\u001b[39mfit_generator(generator\u001b[39m=\u001b[39mtrain_ds,epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2508\u001b[0m     generator,\n\u001b[0;32m   2509\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2510\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2511\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2512\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2513\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2514\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2515\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2516\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2517\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2518\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2519\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2520\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2521\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2522\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file013w81ye.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mhalama\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_13\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# train_generator=train_datagen.flow_from_directory('C:/Users/Ferhat/Python Code/Workshop/Tensoorflow transfer learning/downloads',\n",
    "#                                                  target_size=(224,224),\n",
    "#                                                  color_mode='rgb',\n",
    "#                                                  batch_size=32,\n",
    "#                                                  class_mode='categorical')\n",
    "\n",
    "#tutaj jest coś źle\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True, \n",
    ")\n",
    "\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(generator=train_ds,epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
